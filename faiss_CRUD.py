import os
from PIL import Image
import torch
import numpy as np
from tqdm import tqdm
from torchvision import transforms
from facenet_pytorch import InceptionResnetV1
from ultralytics import YOLO
import pillow_heif
import uuid
import faiss

# ‚úÖ ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô langchain_community ‡∏ï‡∏≤‡∏° v0.2+
from langchain_community.vectorstores import FAISS
from langchain.docstore.document import Document
from langchain.embeddings.base import Embeddings
from langchain_community.docstore.in_memory import InMemoryDocstore
from faiss import IndexFlatL2
import os

# Get the current working directory
current_path = os.getcwd()
print("Current Working Directory:", current_path)

pillow_heif.register_heif_opener()


class DummyEmbeddings(Embeddings):
    def embed_documents(self, texts):
        return texts

    def embed_query(self, text):
        return text


class FaceVectorDatabase:
    def __init__(self, device=None):
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")
        self.dim = 512
        self.model = InceptionResnetV1(pretrained="vggface2").eval().to(self.device)
        self.face_detector = YOLO(
            os.path.join(f"{current_path}", "model/yolov11n-face.pt")
        )
        self.faiss_storage_path = os.path.join(f"{current_path}", "data/faiss_Store")
        self.data_path = os.path.join(f"{current_path}", "data/person_img")
        self.update_path = os.path.join(f"{current_path}", "data/person_img_update")
        self.transform = transforms.Compose(
            [
                transforms.Resize((160, 160)),
                transforms.ToTensor(),
                transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),
            ]
        )

    def extract_face_vectors(self, image_folder):
        """
        image_folder (image_person / image_person_update) : folder ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏∞‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÄ‡∏≠‡∏≤‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å folder ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡πÅ‡∏ö‡∏ö

        ‚îú‚îÄ‚îÄ person_img/
        ‚îÇ ‚îú‚îÄ‚îÄ name1/
        ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ 1.jpg
        ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ 2.jpg
        ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ 3.jpg
        ‚îÇ ‚îú‚îÄ‚îÄ name2/
        ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ 1.jpg
        ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ 2.jpg
        ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ 3.jpg
        ‚îÇ ‚îî‚îÄ‚îÄ ...

        vectors : ‡πÉ‡∏ä‡πâ‡πÄ‡∏Å‡πá‡∏ö vector ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ö‡∏µ‡∏ö‡∏≠‡∏±‡∏î‡πÅ‡∏•‡πâ‡∏ß
        doc     :
        """

        vectors = []
        docs = []

        for folder_person_name in tqdm(
            os.listdir(image_folder), desc=f"Processing {image_folder}"
        ):
            # path ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö folder ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏ô ‡πÄ‡∏ä‡πà‡∏ô Pun ‡∏Ç‡πâ‡∏≤‡∏á‡πÉ‡∏ô‡∏°‡∏µ‡∏†‡∏≤‡∏û
            person_folder = os.path.join(image_folder, folder_person_name)
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏†‡∏≤‡∏û‡πÉ‡∏ô folder ‡∏Å‡πá‡πÑ‡∏õ‡∏´‡∏≤ folder ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ
            if not os.path.isdir(person_folder):
                continue
            # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡πÄ‡∏≠‡∏≤‡∏†‡∏≤‡∏û‡∏°‡∏≤‡∏ö‡∏µ‡∏ö vector
            for img_file in os.listdir(person_folder):
                # ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏†‡∏≤‡∏û‡πÉ‡∏ô folder ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏ô‡∏ô‡∏±‡πâ‡∏ô‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏ú‡πà‡∏≤‡∏ô path person_folder
                img_path = os.path.join(person_folder, img_file)

                try:
                    img = Image.open(img_path).convert("RGB")  # ‡πÅ‡∏õ‡∏•‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πâ‡∏ô RGB ‡∏Å‡πà‡∏≠‡∏ô
                except Exception as e:
                    print(f"[!] Error loading image: {img_path} | {e}")
                    continue

                """
                YOLO FUNCTION DETECT FACE AND CROPPED FACE
                """

                # Detect face YOLO
                results = self.face_detector.predict(
                    source=img, conf=0.8, verbose=False
                )
                detections = results[0]

                if not detections.boxes or len(detections.boxes) == 0:
                    print(f"[!] No face found in: {img_path}")
                    continue

                x1, y1, x2, y2 = map(int, detections.boxes[0].xyxy[0])
                cropped = img.crop((x1, y1, x2, y2))
                face_tensor = self.transform(cropped).unsqueeze(0).to(self.device)

                with torch.no_grad():
                    embedding = self.model(face_tensor).squeeze().cpu().numpy()
                    embedding = embedding / np.linalg.norm(embedding)  # Normalize
                    # ‡πÄ‡∏Å‡πá‡∏ö vector ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ö‡∏µ‡∏ö‡∏≠‡∏±‡∏î‡πÑ‡∏ß‡πâ‡πÉ‡∏ô list vector,doc
                    vectors.append(embedding)
                    docs.append(
                        Document(
                            page_content="face_vector",
                            metadata={"name": folder_person_name, "image": img_file},
                        )
                    )
        return vectors, docs

    """
    ================================CREATE================================
    """

    def create_empty_faiss(self):
        """
        index    : ‡∏™‡∏£‡πâ‡∏≤‡∏á vector ‡∏Ç‡∏ô‡∏≤‡∏î 512
        docstore : ‡∏™‡∏£‡πâ‡∏≤‡∏á ‡∏ó‡∏µ‡πà‡∏ß‡πà‡∏≤‡∏á ‡πÜ ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö metadata ‡πÄ‡∏ä‡πà‡∏ô ‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡πÅ‡∏•‡∏∞‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå
        index_to_docstore_id : dictionary mapping ‡∏à‡∏≤‡∏Å index ‡πÉ‡∏ô FAISS ‡πÑ‡∏õ‡∏¢‡∏±‡∏á ID ‡πÉ‡∏ô docstore

        db
        index: FAISS index ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏î‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå
        docstore: ‡πÄ‡∏Å‡πá‡∏ö metadata ‡πÄ‡∏ä‡πà‡∏ô ‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏ô‡πÅ‡∏•‡∏∞‡∏ä‡∏∑‡πà‡∏≠‡∏£‡∏π‡∏õ
        index_to_docstore_id: mapping ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á index ‡∏Å‡∏±‡∏ö ID ‡πÉ‡∏ô docstore
        """

        index = faiss.IndexIDMap(faiss.IndexFlatL2(self.dim))  # ‡πÉ‡∏ä‡πâ IndexIDMap
        docstore = InMemoryDocstore({})
        index_to_docstore_id = {}
        db = FAISS(
            embedding_function=DummyEmbeddings(),
            index=index,
            docstore=docstore,
            index_to_docstore_id=index_to_docstore_id,
        )
        db.save_local(self.faiss_storage_path)
        print("[‚úÖ] Empty FAISS database created and saved.")

    def build_faiss(self, batch_size=5):
        """
        batch_size : ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô batch ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ RAM
        index : ‡∏™‡∏£‡πâ‡∏≤‡∏á IndexFlatL2 -‡∏Ç‡∏ô‡∏≤‡∏î 512
        index.add : ‡πÄ‡∏≠‡∏≤ vector ‡∏ó‡∏µ‡πà extract ‡∏°‡∏≤‡πÑ‡∏õ‡πÉ‡∏™‡πà ‡πÉ‡∏ô index
        docstore : loop ‡πÄ‡∏≠‡∏≤ vector ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô index ‡∏°‡∏≤‡πÄ‡∏Å‡πá‡∏ö‡πÉ‡∏ô docstore

        doc_ids : ‡πÄ‡∏Å‡πá‡∏ö uuid ‡∏ï‡∏≤‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô vector ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å image_person
        docstore_dict : ‡πÄ‡∏õ‡πá‡∏ô unique id ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏†‡∏≤‡∏û
        index_to_docstore_id : ‡∏™‡∏™‡∏£‡πâ‡∏≤‡∏á dictionary ‡∏ó‡∏µ‡πà mapping ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á ‡∏•‡∏≥‡∏î‡∏±‡∏ö index ‡πÉ‡∏ô FAISS ‡∏Å‡∏±‡∏ö ID ‡∏Ç‡∏≠‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÉ‡∏ô docstore
        """
        vectors, docs = self.extract_face_vectors(self.data_path)
        if not vectors:
            print("[‚ùó] No face vectors extracted.")
            return

        index = faiss.IndexIDMap(faiss.IndexFlatL2(self.dim))
        ids = np.array(range(len(vectors)), dtype=np.int64)  # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î ID ‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö
        for i in range(0, len(vectors), batch_size):
            batch_vecs = np.array(vectors[i : i + batch_size]).astype(np.float32)
            batch_ids = ids[i : i + batch_size]
            index.add_with_ids(batch_vecs, batch_ids)

        docstore_dict = {}
        index_to_docstore_id = {}
        for i, doc in enumerate(docs):
            doc_id = str(uuid.uuid4())
            docstore_dict[doc_id] = doc
            index_to_docstore_id[i] = doc_id  # mapping FAISS idx -> doc_id

        db = FAISS(
            embedding_function=DummyEmbeddings(),
            index=index,
            docstore=InMemoryDocstore(docstore_dict),
            index_to_docstore_id=index_to_docstore_id,
        )
        db.save_local(self.faiss_storage_path)
        print("[‚úÖ] FAISS database built with IndexIDMap and saved.")

    """
    ================================UPDATE================================
    """

    def update_faiss(self):
        """
        db
        load model vector : ‡πÄ‡∏î‡∏¥‡∏°‡∏°‡∏≤‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÄ‡∏õ‡πá‡∏ô base

        existing_keys : ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤ Metadata={'name': 'Pun', 'image': 'IMG_6371.HEIC'}
        ‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏•‡∏∞‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô model ‡∏°‡∏±‡πâ‡∏¢


        """
        db = FAISS.load_local(
            self.faiss_storage_path,
            embeddings=DummyEmbeddings(),
            allow_dangerous_deserialization=True,
        )
        existing_keys = {
            f"{doc.metadata['name']}_{doc.metadata['image']}"
            for doc in db.docstore._dict.values()
        }

        new_vectors, new_docs = self.extract_face_vectors(self.update_path)
        if not new_vectors:
            print("[‚ùó] No new faces to add.")
            return

        filtered_vectors = []
        filtered_docs = []
        for vec, doc in zip(new_vectors, new_docs):
            key = f"{doc.metadata['name']}_{doc.metadata['image']}"
            if key not in existing_keys:
                filtered_vectors.append(vec)
                filtered_docs.append(doc)
                existing_keys.add(key)

        if not filtered_vectors:
            print("[‚ÑπÔ∏è] All vectors already exist in FAISS.")
            return

        current_count = db.index.ntotal
        ids = np.array(
            range(current_count, current_count + len(filtered_vectors)), dtype=np.int64
        )
        db.index.add_with_ids(np.array(filtered_vectors).astype(np.float32), ids)

        # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï docstore ‡πÅ‡∏•‡∏∞ index_to_docstore_id
        for i, (vec, doc) in enumerate(zip(filtered_vectors, filtered_docs)):
            doc_id = str(uuid.uuid4())
            db.docstore._dict[doc_id] = doc
            db.index_to_docstore_id[current_count + i] = doc_id

        db.save_local(self.faiss_storage_path)

    """
    ================================DELETE================================
    """

    def delete_vectors_by_name(self, name_to_delete):
        """
        ‡πÄ‡∏ä‡πá‡∏Ñ‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠ ‡∏ß‡πà‡∏≤‡πÉ‡∏ô metadata ‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡∏ô‡∏±‡πâ‡∏ô‡∏°‡∏±‡πâ‡∏¢ ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ ‡∏•‡∏ö
        """
        db = FAISS.load_local(
            self.faiss_storage_path,
            embeddings=DummyEmbeddings(),
            allow_dangerous_deserialization=True,
        )

        indices_to_delete = []
        for idx, doc_id in db.index_to_docstore_id.items():
            doc = db.docstore.search(doc_id)
            if doc.metadata.get("name") == name_to_delete:
                faiss_id = idx  # ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ idx ‡∏Ñ‡∏∑‡∏≠ FAISS ID ‡∏à‡∏£‡∏¥‡∏á‡πÜ
                indices_to_delete.append(faiss_id)

        if not indices_to_delete:
            print(f"[‚ùó] No vectors found with name '{name_to_delete}'.")
            return

        print(
            f"[üóëÔ∏è] Deleting {len(indices_to_delete)} vectors for '{name_to_delete}'..."
        )
        db.index.remove_ids(np.array(indices_to_delete, dtype=np.int64))

        # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï docstore ‡πÅ‡∏•‡∏∞ index_to_docstore_id
        remaining_index_map = {}
        remaining_docstore = {}
        for idx, doc_id in db.index_to_docstore_id.items():
            if idx not in indices_to_delete:
                remaining_index_map[idx] = doc_id
                remaining_docstore[doc_id] = db.docstore.search(doc_id)

        db.docstore = InMemoryDocstore(remaining_docstore)
        db.index_to_docstore_id = remaining_index_map

        db.save_local(self.faiss_storage_path)

    """
    ================================GET================================
    """

    def get_total_face_count(self):
        """
        ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô FAISS database
        """
        db = FAISS.load_local(
            self.faiss_storage_path,
            embeddings=DummyEmbeddings(),
            allow_dangerous_deserialization=True,
        )
        total_count = db.index.ntotal
        print(f"[üìä] Total face vectors in FAISS: {total_count}")
        return total_count

    def get_person_vectors(self, person_name):
        """
        database ‡∏°‡∏µ person_name(‡∏ä‡∏∑‡πà‡∏≠‡∏ô‡∏±‡πâ‡∏ô‡∏Å‡∏µ‡πà‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á)
        """
        db = FAISS.load_local(
            self.faiss_storage_path,
            embeddings=DummyEmbeddings(),
            allow_dangerous_deserialization=True,
        )
        results = []
        for idx, doc_id in db.index_to_docstore_id.items():
            doc = db.docstore.search(doc_id)
            if doc.metadata.get("name") == person_name:
                result_info = {"index": idx, "doc_id": doc_id, "metadata": doc.metadata}
                results.append(result_info)
                print(
                    f"[üîç] Found vector: Index={idx}, Doc ID='{doc_id}', Metadata={doc.metadata}"
                )
        print(f"[‚ÑπÔ∏è] Total vectors found for '{person_name}': {len(results)}")
        return results


if __name__ == "__main__":
    db_manager = FaceVectorDatabase()

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á FAISS database empty ‡∏£‡∏≠ add ‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏´‡∏°‡πà
    # db_manager.create_empty_faiss()

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á FAISS database ‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û‡πÉ‡∏ô person_img/
    db_manager.build_faiss()

    # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å person_img_update/
    # db_manager.update_faiss()

    # ‡∏•‡∏ö‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏Ç‡∏≠‡∏á‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•
    # db_manager.delete_vectors_by_name("Pun")

    # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏Ç‡∏≠‡∏á‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏´‡∏ô‡∏∂‡πà‡∏á
    # db_manager.get_total_face_count() #‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏°‡∏µ‡∏Å‡∏µ‡πà‡∏Ñ‡∏ô
    # db_manager.get_person_vectors("Pun") ‡∏Ñ‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
